{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from atrader import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "code = get_code_list_set('SZAG','2005-01-01','2019-05-31')\n",
    "data = pd.read_csv('../data/szag_050101_190531.csv')\n",
    "data = data.merge(code[['code','name']], on='code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_asset_code(df,name_col,thresh_hold):\n",
    "    '''\n",
    "    get assets that have trade records more than thresh_hold\n",
    "    '''\n",
    "    count_trade = df.groupby('name',as_index=False).agg({'close':'count'})\n",
    "    count_trade = count_trade[count_trade.close>thresh_hold]\n",
    "    count_trade['is_ST_or_S'] = count_trade['name'].apply(lambda x: 1 \\\n",
    "                                                          if x.startswith('*') or x.startswith('S') else 0)\n",
    "    count_trade = count_trade[count_trade.is_ST_or_S==0]\n",
    "    return count_trade\n",
    "\n",
    "def get_valid_asset(df,asset_code,last_date):\n",
    "    '''\n",
    "    get assets whose last trade time are later than last_date\n",
    "    '''\n",
    "    df = df[df.name.isin(asset_code)]\n",
    "    df = df.sort_values(['time'])\n",
    "    last_trade_time = df.groupby(['name'],as_index=False)['time'].last()\n",
    "    last_trade_time['time'] = pd.to_datetime(last_trade_time['time'], format='%Y-%m-%d')\n",
    "    last_trade_time = last_trade_time[last_trade_time.time>=pd.to_datetime(last_date)]\n",
    "    return last_trade_time\n",
    "\n",
    "def get_lag_feat(df,feat,gb_c,lag):\n",
    "    '''\n",
    "    get lag features\n",
    "    '''\n",
    "    df = df.sort_values(gb_c+['time'])\n",
    "    df['lag_'+str(np.abs(lag))+'_'+str(feat)] = df.groupby(gb_c)[feat].shift(lag)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['time'] = pd.to_datetime(data['time'])\n",
    "data = data.sort_values(['name','time'])\n",
    "asset_code = get_asset_code(data,'name',3000)\n",
    "valid_asset = get_valid_asset(data, asset_code.name.unique(), '2019-05-28 15:00:00')\n",
    "data = data.merge(valid_asset[['name']], on='name')\n",
    "data = get_lag_feat(data, 'close', ['name'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build model\n",
    "#### train val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = data.name.unique()\n",
    "dates = np.sort(data.time.unique())\n",
    "\n",
    "train_dates = dates[:3000]\n",
    "val_dates = dates[3000:]\n",
    "\n",
    "num_cols = ['return_1d']\n",
    "cat_cols = ['is_null']\n",
    "cat_dim = {}\n",
    "cat_dim['is_null'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training set generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Hyper param\n",
    "INP_DIM = 1\n",
    "EMB_DIM = 10\n",
    "SEQ_LEN = 10\n",
    "OUT_DIM = 1\n",
    "\n",
    "i = 0\n",
    "frames = pd.DataFrame(product(assets, dates[i:i+SEQ_LEN+1]),columns=['name','time'])\n",
    "train_df = frames.merge(data[['name','time','close','lag_1_close']], on=['name','time'], how='left')\n",
    "train_df['return_1d'] = (train_df['close']-train_df['lag_1_close'])/train_df['lag_1_close']\n",
    "train_df['is_null'] = 0\n",
    "train_df.loc[train_df['return_1d'].isnull()==True, 'is_null'] = 1\n",
    "train_df['return_1d'] = train_df['return_1d'].fillna(0)\n",
    "\n",
    "\n",
    "X = {}\n",
    "\n",
    "num_X = []\n",
    "for col in num_cols:\n",
    "    num_X.append(pd.pivot_table(train_df[['name','time','return_1d']], values='return_1d', columns='time',index='name').values[:,:-1] )\n",
    "num_X = np.vstack(num_X).reshape(-1,SEQ_LEN,1)\n",
    "X['num'] = num_X\n",
    "\n",
    "for col in cat_cols:\n",
    "    X[col] =  pd.pivot_table(train_df[['name','time',col]], values=col, columns='time',index='name').values[:,:SEQ_LEN]\n",
    "    cat_dim[col] = len(train_df[col].unique())\n",
    "train_y = pd.pivot_table(train_df[['name','time','return_1d']], values='return_1d', columns='time',index='name').values[:,1:]\n",
    "train_y = train_y.reshape(-1,SEQ_LEN,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "num (InputLayer)                (702, 10, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "is_null (InputLayer)            (702, 10)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  (702, 10, 10)        480         num[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (702, 10, 10)        20          is_null[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (702, 10, 20)        0           lstm_18[0][0]                    \n",
      "                                                                 embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_19 (LSTM)                  (702, 10, 64)        21760       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lstm_20 (LSTM)                  (702, 10, 1)         264         lstm_19[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,524\n",
      "Trainable params: 22,524\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import  *\n",
    "from keras.callbacks import *\n",
    "from keras.models import *\n",
    "\n",
    "# define batch size(always train with all assets within a trading day)\n",
    "BS = len(train_df.name.unique())\n",
    "\n",
    "num_in = Input(batch_shape=(BS,SEQ_LEN,INP_DIM),name='num')\n",
    "num_lstm = LSTM(EMB_DIM*len(cat_cols),return_sequences=True)(num_in)\n",
    "cat_in = [Input(batch_shape=(BS,SEQ_LEN),name=x) for x in cat_cols]\n",
    "cat_emb = []\n",
    "for i,col in enumerate(cat_cols):\n",
    "    cat_emb.append(Embedding(cat_dim[col], EMB_DIM)(cat_in[i]))\n",
    "X_in = Concatenate()([num_lstm]+cat_emb)\n",
    "lstm_out = LSTM(64,return_sequences=True)(X_in)\n",
    "final_out = LSTM(OUT_DIM, return_sequences=True)(lstm_out)\n",
    "\n",
    "model = Model(inputs=[num_in]+cat_in, outputs=final_out)\n",
    "model.summary()\n",
    "model.compile(loss='mse',optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.1474e-04\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1364e-04\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.1412e-04\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.1362e-04\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.1340e-04\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.1356e-04\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.1288e-04\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.1291e-04\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.1280e-04\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.1267e-04\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.1269e-04\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.1252e-04\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.1249e-04\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.1242e-04\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.1230e-04\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1228e-04\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.1216e-04\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.1211e-04\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.1204e-04\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.1194e-04\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.1191e-04\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.1181e-04\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.1175e-04\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1168e-04\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.1160e-04\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.1155e-04\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.1146e-04\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.1141e-04\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.1134e-04\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.1127e-04\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1121e-04\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.1113e-04\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1108e-04\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1100e-04\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.1094e-04\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.1087e-04\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1081e-04\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.1075e-04\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.1068e-04\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.1062e-04\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.1055e-04\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.1049e-04\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.1042e-04\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1036e-04\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.1030e-04\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1024e-04\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1018e-04\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.1011e-04\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1005e-04\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0999e-04\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0993e-04\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0987e-04\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.0981e-04\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.0975e-04\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.0969e-04\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.0963e-04\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.0957e-04\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.0951e-04\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.0945e-04\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.0939e-04\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.0933e-04\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0927e-04\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.0921e-04\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.0915e-04\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0909e-04\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.0904e-04\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.0898e-04\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.0892e-04\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.0886e-04\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.0880e-04\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.0875e-04\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0869e-04\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.0863e-04\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.0857e-04\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.0852e-04\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.0846e-04\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.0840e-04\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0835e-04\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.0829e-04\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.0823e-04\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.0818e-04\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.0812e-04\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.0807e-04\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.0801e-04\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.0796e-04\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.0790e-04\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0785e-04\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0779e-04\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0774e-04\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0768e-04\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.0763e-04\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.0757e-04\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.0752e-04\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.0746e-04\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.0741e-04\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.0735e-04\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.0730e-04\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.0725e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.0719e-04\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.0714e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d7fdbef630>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='loss',patience=10)\n",
    "red_lr = ReduceLROnPlateau(monitor='loss',min_lr=0.0005,patience=5)\n",
    "model.fit(X, train_y,steps_per_epoch=1, epochs=100,callbacks=[es,red_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_5:0' shape=(702, 10, 1) dtype=float32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
